{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Linear Regression Case\n",
    "Oefening Data Scientist \n",
    "Geert Vandezande\n",
    "\n",
    "Doel:\n",
    "- Supervised Learning toepassen\n",
    "- EDA uitvoeren op een dataset\n",
    "- Lineair Regression toepassen op de data: de target is beter doen dan r² = 80% nauwkeurigheid die in de meeste uitwerkingen zit...\n",
    "- Ook door andere vormen van regressie toe te passen, het doel is om r² zo goed mogelijk te krijgen\n",
    "\n",
    "\n",
    "\n",
    "Extra:\n",
    "- er wordt logging voorzien voor en na de belangrijke stappen (zie LinReg_logging.log). Hiermee kunnen de stappen en de resultaten opgevolgd worden. Dit wordt in de LinReg_logging weg geschreven\n",
    "- we hebben een aantal herbruikbare code-blokken in een functie gestoken\n",
    "- een aparte class gemaakt voor BinaryValueEncoders om eens te proberen (kan uiteraard met de OneHotEncoder)\n",
    "- we hebben een functie geschreven om snel een reeks van modellen te kunnen evalueren, zowel zonder pipelining als met pipelining\n",
    "\n",
    "Dataset: \n",
    "- More info: see kaggle https://www.kaggle.com/datasets/mirichoi0218/insurance/data\n",
    "\n",
    "Metadata :\n",
    "- age: age of primary beneficiary\n",
    "- sex: insurance contractor gender, female, male\n",
    "- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "- children: Number of children covered by health insurance / Number of dependents\n",
    "- smoker: Smoking\n",
    "- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "- charges: Individual medical costs billed by health insurance\n",
    "\n",
    "\n",
    "Volgorde van activiteiten in deze notebook: (cfr Datacamp \"preparing data for modelling)\n",
    "- data inlezen\n",
    "- data bekijken, visueel en numerisch\n",
    "- data summarizen via summarytools \n",
    "- missing en duplicated data oplossen \n",
    "- incorrect types controleren\n",
    "- numerische waarde standardizeren\n",
    "- categorische varaiabelen processen\n",
    "- feature engineering checken\n",
    "- linear, ridge, lasso, gradient boost, random forest,...  modellen uitvoeren\n",
    "- alle modellen worden toegepast op 2 situaties voor stratefy\n",
    "    - Train_test_split zonder stratify\n",
    "    - Train_test_split met stratefy op basis van de categorisatie van de charges (target v) (omdat er skewness is op charges )\n",
    "\n",
    "- zowel met hyper parameter tuning en zonder\n",
    "\n",
    "- extra test: met verwijderen van outliers in BMI ==> geen beter resultaat\n",
    "- enkel rokers: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import van de diverse modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "\n",
    "\n",
    "# Machine learning algorithm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "\n",
    "# system utils\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from colorama import Fore, Back, Style\n",
    "import sys\n",
    "import os\n",
    "import chardet\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra code snippits die doorheen de notebook gebruikt worden:\n",
    "\n",
    "save_fig: na generatie van een image kan de image naar file geschreven worden in de images/.. directory. Geef steeds een zinvolle naam\n",
    "\n",
    "read_JSON: om eenvoudig een JSON in te lezen\n",
    "\n",
    "log_info:\n",
    "- logging functie om doorheen de notebooks de status naar file te kunnen schrijven. \n",
    "- de logstatements worden tijdens de uitvoering van de code bewaard in een list. Die kan tussentijds naar het scherm geprint worden of naar een file\n",
    "- log_info_write_to_file: schrijf de loginformatie naar file \n",
    "- log_info_print_on_screen: print alle loginfo naar het scherm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkele extra code snippets gebruikt doorheen de oefening\n",
    "\n",
    "# to plot or not to plot - zet op True om de plots te zien, zet op False om de plots niet te zien bij een Run ALL\n",
    "plot_graphs = True\n",
    "\n",
    "# schrijf een visual naar file\n",
    "\n",
    "IMAGES_PATH = Path() / \"images\" \n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Lezen van de JSON-file\n",
    "\n",
    "def read_JSON(file_path_read):\n",
    "    with open(file_path_read, 'r') as file:\n",
    "        files_from_json = json.load(file)\n",
    "    return files_from_json\n",
    "\n",
    "\n",
    "# functies om te loggen naar file\n",
    "log_info_lijst = []\n",
    "log_filenaam = \"LinReg_continue.log\"\n",
    "\n",
    "if os.path.exists(log_filenaam):\n",
    "    os.remove(log_filenaam)\n",
    "\n",
    "def log(log_code=\"INFO\", boodschap=\"euh geen boodschap????\"):\n",
    "    global log_info_lijst\n",
    "    now = datetime.datetime.now()\n",
    "    formatted_date = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    log_message = f\"{Style.RESET_ALL}{formatted_date} : {log_code} : {boodschap}\"\n",
    "    log_info_lijst.append(log_message)\n",
    "    with open(log_filenaam, 'a') as file:  # Open the file in append mode\n",
    "        file.write(str(boodschap) + '\\n')  # Voeg een nieuwe regel toe na elke string\n",
    "    print(log_message)\n",
    "    return\n",
    "\n",
    "def log_info(boodschap):\n",
    "    log(\"Info\",boodschap)\n",
    "    def log_info_write_to_file(filename):\n",
    "        with open(filename, 'a') as file:  # Open the file in append mode\n",
    "            for string in log_info_lijst:\n",
    "                file.write(string + '\\n')  # Voeg een nieuwe regel toe na elke string\n",
    "        return\n",
    "\n",
    "def log_info_write_to_file(filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for string in log_info_lijst:\n",
    "            file.write(string + '\\n')  # Voeg een nieuwe regel toe na elke string\n",
    "    return\n",
    "\n",
    "def log_info_print_on_screen():\n",
    "    for boodschap in log_info_lijst:\n",
    "        print(boodschap)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippets om visuals op het scherm te plaatsen\n",
    "Deze worden doorheen de notebook gebruikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie: maakt een boxplot van kolommen in een pandaframe\n",
    "# df_col is een list van de kolomnamen die geplot worden\n",
    "def plot_boxplot(df, df_col, filenaam):\n",
    "    if plot_graphs:\n",
    "        # boxplot van de numerische waarden\n",
    "        sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "        plt.figure(figsize=(15, 10)) \n",
    "        for i, col in enumerate(df_col):\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 1)\n",
    "            sns.boxplot(x=df[col], orient='h', linewidth=1.5)\n",
    "            plt.title(f\"Boxplot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 2)\n",
    "            sns.histplot(df[col], kde=True,  linewidth=1)\n",
    "            plt.title(f\"Distribution Plot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "            plt.ylabel(\"Density\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig(filenaam)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hulpfuncties\n",
    "\n",
    "bereken_percentage_outliers: via Isolation forest wordt het percentage van de outliers berekend.\n",
    "- df : dataframe\n",
    "- columns_to_use: list van koloms die gebruikt worden om de outliers te berekenen\n",
    "- functie geeft een percentage terug van het aaantal outliers op het totaal aantal observaties\n",
    "\n",
    "\n",
    "cap_values: vervang outliers door hun lower of upperpercentieel waarde: de whiskers worden berekend door van de lower_percentieel waarde een waarde af te trekken gelijk aan 1,5 * IQR (interquartile range), voor upper_percentieel waarde wordt de 1,5 * IQR bijgeteld\n",
    "- df: dataframe\n",
    "- columns_to_use\n",
    "- lower_percentieel (default = 25)\n",
    "- upper_percentieel (default = 75)\n",
    "\n",
    "\n",
    "BinaryValueEncoder: hulp klasse om categorische te classificeren naar 0 en 1\n",
    "- string_zero: indien categorische waarde = string_zero, krijgt de nieuwe waarde 0\n",
    "- string_one: indien categorische waarde = string_zero, krijgt de nieuwe waarde 1\n",
    "Try-out om zelf eens een class te schrijven voor transformation. Kan uiteraard ook via OneHotEncoding gedaan worden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie om het percentage outliers te berkenen voor een set van kolommen in een dataframe\n",
    "def bereken_percentage_aantal_outliers(df , columns_to_use):\n",
    "    # Initialiseren van het Isolation Forest model\n",
    "    iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "\n",
    "    # Fit het model\n",
    "    iso_forest.fit(df[columns_to_use])\n",
    "    # Voorspellingen\n",
    "    # Het geeft -1 voor outliers en 1 voor inliers\n",
    "    labels = iso_forest.predict(df[columns_to_use])\n",
    "    # Toevoegen van de labels aan het DataFrame om outliers te identificeren\n",
    "    df_intern = df.copy()\n",
    "    df_intern['outlier'] = labels\n",
    "    outliers = df_intern[df_intern['outlier'] == -1]\n",
    "    aantal_outliers = df_intern['outlier'].value_counts()\n",
    "    print(aantal_outliers)\n",
    "    percentage_aantal_outliers = (len(outliers) / len(df_intern)) * 100\n",
    "\n",
    "    return percentage_aantal_outliers\n",
    "\n",
    "# functie om outliers in een kolom te cappen op een percentiel waarde\n",
    "def cap_values(df_input, column, lower_percentile=25, upper_percentile=75):\n",
    "    # voeg code toe om beter de outliers te verwijderen\n",
    "    log(\"Info\", f\"Capping values voor kolom {column} naar lower percentiel {lower_percentile} - upper percentiel {upper_percentile}\")\n",
    "    q1, q3 = np.percentile(df_input[column], [lower_percentile, upper_percentile])  # Calculate the 25th (Q1) and 75th (Q3) percentiles\n",
    "    iqr = q3 - q1  # Calculate the interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower whisker (Q1 - 1.5 * IQR)\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper whisker (Q3 + 1.5 * IQR)\n",
    "\n",
    "    # lower_bound = df[column].quantile(lower_percentile)\n",
    "    # upper_bound = df[column].quantile(upper_percentile)\n",
    "    \n",
    "    # Waarden cappen met behulp van de numpy.where functie\n",
    "    df_output = df_input.copy()\n",
    "    df_output[column] = np.where(df_input[column] < lower_bound, lower_bound, df_input[column])\n",
    "    df_output[column] = np.where(df_input[column] > upper_bound, upper_bound, df_input[column])    \n",
    "    return df_output\n",
    "\n",
    "\n",
    "# hulp klasse om categorische waarden met twee mogelijke waarde naar 0 en 1 om te zetten\n",
    "# was een try-out om zelf eens een encoder te schrijven\n",
    "# kan uiteraard eenvoudiger door OneHotEncoding toe te passen, we hebben dan ook OneHotEncoding toegepast \n",
    "class BinaryValueEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, string_zero=\"nul\", string_one=\"een\"):\n",
    "        # Je kunt hier extra initialisatie toevoegen indien nodig\n",
    "        self.string_zero = string_zero\n",
    "        self.string_one = string_one\n",
    "     \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Er is geen fitting nodig voor deze eenvoudige codering\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X wordt aangenomen een pandas DataFrame te zijn\n",
    "        log(\"Info\", f\"BinaryValueEncoder transform opgeroepen voor One_value {self.string_one} en Zero_value {self.string_zero}\")\n",
    "        X = X.copy()  # Kopieer de DataFrame om wijzigingen te voorkomen in het origineel\n",
    "        X = X.applymap(lambda x: 1 if x == self.string_zero else 0)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        # Dit is een eenvoudige passthrough-voorbeeld, waarbij feature namen niet wijzigen.\n",
    "        if input_features is not None:\n",
    "            return input_features\n",
    "        else:\n",
    "            return np.array(['x{}'.format(i) for i in range(X.shape[1])], dtype=object)\n",
    "\n",
    "\n",
    "# hulpklasse om de waarden van een kolom te normaliseren en in een pipeline te gebruiken\n",
    "class WinsorizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, limits=[0.05, 0.05]):\n",
    "        self.limits = limits\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Niets te fitten, keert zichzelf terug\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return winsorize(X, limits=self.limits)\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        # Genereer en retourneer de lijst met uitvoerfeaturenamen\n",
    "        if input_features is None:\n",
    "            input_features = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "        output_features = [f\"{name}\" for name in input_features]\n",
    "        return output_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twee extra functies om een pipeline uit te voeren:\n",
    "- één zonder hyperparameter tuning\n",
    "- één met hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om op basis van een X_train, X_test, y_train, y_test en de preprocessessin)\n",
    "# return is een dataframe met de resultaten van de verschillende modellen\n",
    "# zonder hyperparameter tuning\n",
    "def excute_regression_models_with_pipeline(X_train, X_test, y_train,y_test,preprocessor):\n",
    "\n",
    "    best_XGB_params = {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
    "    \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Lasso': Lasso(alpha=0.1,random_state=42),\n",
    "        'Ridge': Ridge(alpha=0.01,random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "        'XGBRegressor': XGBRegressor(random_state=42, **best_XGB_params)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('regressor', model)\n",
    "        ]) \n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mape = 100 * mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "        results.append([name, test_rmse, test_r2, test_mape])\n",
    "    df = pd.DataFrame(results, columns=['model', 'test_rmse', 'test_r2', 'test_mape'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Functie om op basis van een X_train, X_test, y_train, y_test en de preprocessor\n",
    "# return is een dataframe met de resultaten van de verschillende modellen\n",
    "# met hyperparameter tuning\n",
    "def execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor):\n",
    "    # Hyperparameters sets voor verschillende modellen\n",
    "\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Lasso': Lasso(alpha=0.1,max_iter=10000, random_state=42),\n",
    "        'Ridge': Ridge(alpha=0.01,random_state=42),\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "        'XGBRegressor': XGBRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        'Lasso': {'regressor__alpha': [0.01, 0.1, 1.0]},\n",
    "        'Ridge': {'regressor__alpha': [0.01, 0.1, 1.0]},\n",
    "        'Random Forest': {'regressor__n_estimators': [50, 100, 200], 'regressor__max_depth': [None, 10, 20]},\n",
    "        'Gradient Boosting': {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.1, 0.05, 0.01]},\n",
    "        'Decision Tree': {'regressor__max_depth': [None, 10, 20]},\n",
    "        'XGBRegressor': {'regressor__n_estimators': [50, 100], 'regressor__max_depth': [3, 5], 'regressor__learning_rate': [0.1, 0.05]}\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "\n",
    "        # Als het model tuning vereist, gebruik GridSearchCV\n",
    "        if name in param_grid:\n",
    "            grid_search = GridSearchCV(pipeline, param_grid[name], cv=5, scoring='neg_mean_squared_error')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred = best_model.predict(X_test)\n",
    "        else:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mape = 100 * mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "        results.append([name, test_rmse, test_r2, test_mape])\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['model', 'test_rmse', 'test_r2', 'test_mape'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier beginnen we er echt met het inlezen van de data en de eerste checks op de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data bestand inlezen\n",
    "\n",
    "insurance_data_filename = 'data/insurance.csv'\n",
    "df = pd.read_csv(insurance_data_filename)\n",
    "log_info(f\"File ingelezen: {insurance_data_filename}\")\n",
    "\n",
    "# check op duplicates, indien zo verwijder direct\n",
    "df.drop_duplicates(inplace=True)\n",
    "df_original = df.copy()\n",
    "duplicate_waarden = df.duplicated().sum()\n",
    "log_info(f\"Check op duplicates na drop \\n{duplicate_waarden}\")\n",
    "\n",
    "# behoudt een copie van de orginele data\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkele eenvoudige controles\n",
    "log_info(f\"df.info : \\n{df.info()}\")\n",
    "log_info(f\"df.describe : \\n{df.describe()}\")\n",
    "\n",
    "# geen nulwaarden \n",
    "\n",
    "from summarytools import dfSummary\n",
    "dfSummary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drie categorische features: smoking, region en sex\n",
    "# vier numerische features waaronder de target variabele \"charges\"\n",
    "# maak de datasets aan \n",
    "\n",
    "df_cat_col = ['smoker','region','sex']\n",
    "df_num_col = ['age', 'bmi','children']\n",
    "df_label_col = ['charges']\n",
    "\n",
    "# zijn er nominaal categorische variabelen en één ordinal categorische waarden?\n",
    "df_cat_nom_col = ['smoker','region']\n",
    "df_cat_ord_col = list(set(df_cat_col) - set(df_cat_nom_col))\n",
    "\n",
    "df_num = df[df_num_col]\n",
    "df_cat = df[df_cat_col]\n",
    "df_label = df[df_label_col]\n",
    "df_cat_nom = df[df_cat_nom_col]\n",
    "df_cat_ord = df[df_cat_ord_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korte analyze van de categorische variabelen\n",
    "print(df_cat.value_counts())\n",
    "\n",
    "# check op nullen\n",
    "nul_waarden = df.isnull().sum()\n",
    "log_info(f\"Check op nulwaarden \\n{nul_waarden}\")\n",
    "# geen nullen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_num_col,\"Boxplot en histogram van de numerische waarden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_label_col,\"Boxplot en histogram van de target value\")\n",
    "\n",
    "# we zien hier dat er enkele outliers zijn in de kolom charges\n",
    "# we gaan hier rekening mee houden nadien en testen of het aanpakken van de outliers een beter model oplevert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright', hue=col)\n",
    "        plt.title(f\"Count Plot of {col}\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische features countplot\")\n",
    "    plt.show()\n",
    "    log_info(\"Check van categorische features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright', hue='smoker')\n",
    "        plt.title(f\"Count Plot of {col} (Hue: Smoker)\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische variabelen tov smoker\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.pairplot(df, hue='smoker',  kind='reg')\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Numerische features onderlinge scatter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print de correlation nog af tussen de numerische waarden\n",
    "if plot_graphs:\n",
    "    Dataset = df.copy()\n",
    "    Dataset['sex'] = Dataset['sex'].replace(['male','female'],[0,1])\n",
    "    Dataset['smoker'] = Dataset['smoker'].replace(['yes','no'],[1,0])\n",
    "    Dataset['region'] = Dataset['region'].replace(['southwest','southeast','northwest','northeast'],[0,1,2,3])\n",
    "\n",
    "    sns.heatmap(Dataset.corr(),annot=True,cmap='Blues')\n",
    "    plt.title('correlation of Insurance Data')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# enkel tussen smoker en charges is er een duidelijke correlatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preparation - implementatie van een preprocessor pipeline\n",
    "# standard scaler op de numerische waarden, min-max scaler\n",
    "# preprocessor met basic scalen\n",
    "# one hot encoding voor de categorische waarden\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "\n",
    "male_female_transformer = Pipeline(steps=[   \n",
    "    ('male_female_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "smoking_transformer = Pipeline(steps=[  \n",
    "    ('smoking_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "regio_transformer = Pipeline(steps=[\n",
    "    ('regio', OneHotEncoder(drop='first', handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, df_num_col),\n",
    "    (\"male_female\", male_female_transformer, ['sex']), \n",
    "    (\"smoker\", smoking_transformer, ['smoker']), \n",
    "    (\"regio\", regio_transformer, ['region'])],\n",
    "     remainder='passthrough')\n",
    "\n",
    "df_features = df_original.drop(['charges'], axis= 1)\n",
    "np_prepared =  preprocessor.fit_transform(df_features)\n",
    "\n",
    "df_prepared = pd.DataFrame(\n",
    "    np_prepared,\n",
    "    #columns=preprocessing.get_feature_names_out(),\n",
    "    columns = [name.split('__')[-1] for name in preprocessor.get_feature_names_out()],    \n",
    "    index=df_original.index)\n",
    "\n",
    "df_prepared.head()\n",
    "\n",
    "plot_boxplot(df_prepared,df_num_col,\"Boxplot van numerische waarden na standard scaling\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We maken ook een preprocessor om de BMI-waarden te cappen\n",
    "# met behulp van een eigen transformer winsorize \n",
    "\n",
    "num_pipeline_zonder_BMI = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "num_pipeline_BMI = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    ('winsorizer', WinsorizeTransformer()),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "\n",
    "df_num_col_zonder_bmi = ['age', 'children']\n",
    "\n",
    "male_female_transformer = Pipeline(steps=[    \n",
    "    ('male_female_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "smoking_transformer = Pipeline(steps=[    \n",
    "    ('smoking_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "regio_transformer = Pipeline(steps=[\n",
    "    ('regio', OneHotEncoder(drop='first', handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor_bmi = ColumnTransformer([\n",
    "    (\"num\", num_pipeline_zonder_BMI, df_num_col_zonder_bmi),\n",
    "    (\"BMI\", num_pipeline_BMI, ['bmi']),\n",
    "    (\"male_female\", male_female_transformer, ['sex']), \n",
    "    (\"smoker\", smoking_transformer, ['smoker']), \n",
    "    (\"regio\", regio_transformer, ['region'])],\n",
    "     remainder='passthrough')\n",
    "\n",
    "df_features = df_original.drop(['charges'], axis= 1)\n",
    "np_prepared =  preprocessor_bmi.fit_transform(df_features)\n",
    "\n",
    "print(df_prepared.columns)\n",
    "\n",
    "df_prepared = pd.DataFrame(\n",
    "    np_prepared,\n",
    "    #columns=preprocessing.get_feature_names_out(),\n",
    "    columns = [name.split('__')[-1] for name in preprocessor_bmi.get_feature_names_out()],    \n",
    "    index=df_original.index)\n",
    "\n",
    "df_prepared.head()\n",
    "\n",
    "plot_boxplot(df_prepared, df_num_col,\"Boxplot van numerische waarden na standard scaling en robuust scaling van BMI\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan nu de train_test_split testen.\n",
    "De \"charges\" zijn niet standard verdeeld. \n",
    "We gaan een stratify uitvoeren op de charges maar bins-gewijs.\n",
    "\n",
    "Eerst checken we de gewone train_test_split zonder stratefy.\n",
    "Dan checken we de train_test_split met stratefy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken van de verdeling van de y_train en y_test\n",
    "\n",
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Plot histogrammen voor y_train en y_test\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(y_train, bins=30, alpha=0.5, label='y_train', color='blue')\n",
    "plt.hist(y_test, bins=30, alpha=0.5, label='y_test', color='red')\n",
    "plt.title('Histogram van y_train en y_test')\n",
    "plt.xlabel('Waarden')\n",
    "plt.ylabel('Frequentie')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "save_fig(\"Histogram van y_train en y_test zonder stratefy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken van de verdeling van de y_train en y_test na stratify \n",
    "\n",
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "# Plot histogrammen voor y_train en y_test\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(y_train, bins=30, alpha=0.5, label='y_train', color='blue')\n",
    "plt.hist(y_test, bins=30, alpha=0.5, label='y_test', color='red')\n",
    "plt.title('Histogram van y_train en y_test')\n",
    "plt.xlabel('Waarden')\n",
    "plt.ylabel('Frequentie')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "save_fig(\"Histogram van y_train en y_test met stratefy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We voeren nu de regression uit met behulp van de pipeline functie én voor 6 modellen.\n",
    "De data is niet gestratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eenvoudige regressie  zonder stratefy\n",
    "\n",
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "resultaat = excute_regression_models_with_pipeline(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Regression models with polynomial features, no stratefy\")\n",
    "log_info(\"*************************************************************\")\n",
    "log_info(resultaat_string)\n",
    "log_info(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We voeren nu de regression uit met behulp van de pipeline functie én voor 6 modellen.\n",
    "De data is nu wel gestratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "resultaat = excute_regression_models_with_pipeline(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Regression models with polynomial features, met stratify\\n\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000,50000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nu doen we hetzelfde met hyper parameter tuning.\n",
    "Eens zonder en eens met stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zonder stratify\n",
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "resultaat_eenvoudig_met_pipeline = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat_eenvoudig_met_pipeline, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Regression models with polynomial features en hyperparameter tuning, met stratify\\n\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "resultaat_eenvoudig_met_pipeline = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat_eenvoudig_met_pipeline, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Regression models with polynomial features en hyperparameter tuning, met stratify\\n\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000,50000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat en met hyperparameter tuning\\n\\n\")\n",
    "log_info(resultaat_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we eens testen of er verbetering is als we de outliers in BMI oplossen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "resultaat_eenvoudig_met_pipeline = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor_bmi)\n",
    "resultaat_string = tabulate(resultaat_eenvoudig_met_pipeline, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Zonder outliers in BMI - Regression models with polynomial features, met stratefy\\n\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nu nog een test om enkel niet-rokers en enkel rokers te modelleren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test om alle rokers te verwijderen en terug een check te doen\n",
    "\n",
    "df_no_smokers = df_original[df_original['smoker'] == 'no']\n",
    "\n",
    "X = df_no_smokers.drop(['charges'], axis=1)\n",
    "y = df_no_smokers['charges']\n",
    "\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "resultaat = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"nExtra test: alle rokers verwijderd\\n\")\n",
    "log_info(\"Regression models with polynomial features, met stratefy\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, 50000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test om alle rokers te verwijderen en terug een check te doen\n",
    "\n",
    "df_no_smokers = df_original[df_original['smoker'] == 'yes']\n",
    "\n",
    "X = df_no_smokers.drop(['charges'], axis=1)\n",
    "y = df_no_smokers['charges']\n",
    "\n",
    "y_bins = pd.cut(y, bins=[0, 20000,30000,50000, np.inf], labels=[1, 2, 3, 4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y_bins, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "resultaat = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor)\n",
    "resultaat_string = tabulate(resultaat, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"\\n\\n\")\n",
    "log_info(\"Extra test: alle rokers verwijderd\\n\")\n",
    "log_info(\"Regression models with polynomial features, met stratefy\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, 50000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test om enkel te testen op BMI en charges\n",
    "\n",
    "preprocessor_simple = ColumnTransformer([],\n",
    "     remainder='passthrough')\n",
    "\n",
    "df_no_smokers = df_original[df_original['smoker'] == 'no']\n",
    "\n",
    "X = df_original['bmi'].values.reshape(-1, 1)\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "resultaat = execute_regression_models_with_pipeline_hyperparameter_tuning(X_train, X_test, y_train, y_test, preprocessor_simple)\n",
    "resultaat_string = tabulate(resultaat, headers='keys', tablefmt='psql')\n",
    "\n",
    "log_info(\"Extra test: alle rokers verwijderd\\n\")\n",
    "log_info(\"Regression models with polynomial features, met stratefy\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\\n\\n\")\n",
    "log_info(resultaat_string)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
