{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Linear Regression Case\n",
    "Oefening Data Scientist \n",
    "Geert Vandezande\n",
    "\n",
    "Doel:\n",
    "- Supervised Learning toepassen\n",
    "- EDA uitvoeren op een dataset\n",
    "- Lineair Regression toepassen op de data: target is beter doen dan r² = 80% nauwkeurigheid die in de meeste uitwerkingen zit...\n",
    "- en nadien andere vormen van regressie toepassen, doel is om r² boven de 90% te krijgen\n",
    "\n",
    "==> Resultaat: r² = 90  --- yes, we did it....\n",
    "\n",
    "\n",
    "Extra:\n",
    "- er wordt logging voorzien voor en na de belangrijke stappen (zie LinReg_logging.log). Hiermee kunnen de stappen en de resultaten opgevolgd worden\n",
    "- we hebben een aantal herbruikbare code-blokken in een functie gestoken\n",
    "- een aparta class gemaakt voor BinaryValueEncoders\n",
    "\n",
    "Dataset: \n",
    "- More info: see kaggle https://www.kaggle.com/datasets/mirichoi0218/insurance/data\n",
    "\n",
    "\n",
    "Metadata :\n",
    "- age: age of primary beneficiary\n",
    "- sex: insurance contractor gender, female, male\n",
    "- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "- children: Number of children covered by health insurance / Number of dependents\n",
    "- smoker: Smoking\n",
    "- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "- charges: Individual medical costs billed by health insurance\n",
    "\n",
    "\n",
    "Volgorde van activiteiten in deze notebook: (cfr Datacamp \"preparing data for modelling)\n",
    "- data inlezen\n",
    "- data bekijken, visueel en numerisch\n",
    "- data summarizen via summarytools \n",
    "- missing en duplicated data oplossen \n",
    "- incorrect types controleren\n",
    "- numerische waarde standardizeren\n",
    "- categorische varaiabelen processen\n",
    "- feature engineering\n",
    "- linear Regression toepassen (ook Ridge en Lasso)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import van de diverse modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Machine learning algorithm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import  mean_absolute_percentage_error\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# system utils\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from colorama import Fore, Back, Style\n",
    "import sys\n",
    "import os\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra code snippits die doorheen de notebook gebruikt worden:\n",
    "\n",
    "save_fig: na generatie van een image kan de image naar file geschreven worden in de images/.. directory. Geef steeds een zinvolle naam\n",
    "\n",
    "read_JSON: om eenvoudig een JSON in te lezen\n",
    "\n",
    "log_info:\n",
    "- logging functie om doorheen de notebooks de status naar file te kunnen schrijven. \n",
    "- de logstatements worden tijdens de uitvoering van de code bewaard in een list. Die kan tussentijds naar het scherm geprint worden of naar een file\n",
    "- log_info_write_to_file: schrijf de loginformatie naar file \n",
    "- log_info_print_on_screen: print alle loginfo naar het scherm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkele extra code snippets gebruikt doorheen de oefening\n",
    "\n",
    "plot_graphs = False\n",
    "\n",
    "# schrijf een visual naar file\n",
    "IMAGES_PATH = Path() / \"images\" \n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "# functies om te loggen naar file\n",
    "# Lezen van de JSON-file\n",
    "log_info_lijst = []\n",
    "\n",
    "def read_JSON(file_path_read):\n",
    "    with open(file_path_read, 'r') as file:\n",
    "        files_from_json = json.load(file)\n",
    "    return files_from_json\n",
    "\n",
    "def log(log_code=\"INFO\", boodschap=\"euh geen boodschap????\"):\n",
    "    global log_info_lijst\n",
    "    now = datetime.datetime.now()\n",
    "    formatted_date = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    log_message = f\"{Style.RESET_ALL}{formatted_date} : {log_code} : {boodschap}\"\n",
    "    log_info_lijst.append(log_message)\n",
    "    print(log_message)\n",
    "    return\n",
    "\n",
    "def log_info(boodschap):\n",
    "    log(\"Info\",boodschap)\n",
    "\n",
    "def log_info_write_to_file(filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for string in log_info_lijst:\n",
    "            file.write(string + '\\n')  # Voeg een nieuwe regel toe na elke string\n",
    "    return\n",
    "\n",
    "def log_info_print_on_screen():\n",
    "    for boodschap in log_info_lijst:\n",
    "        print(boodschap)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een boxplot van een kolommen\n",
    "# df_num_col is een list van de kolomnamen die geplot worden\n",
    "\n",
    "def plot_boxplot(df, df_col, filenaam):\n",
    "    if plot_graphs:\n",
    "        # boxplot van de numerische waarden\n",
    "        sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "        plt.figure(figsize=(15, 15)) \n",
    "        for i, col in enumerate(df_col):\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 1)\n",
    "            sns.boxplot(x=df[col], orient='h', linewidth=1.5)\n",
    "            plt.title(f\"Boxplot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 2)\n",
    "            sns.histplot(df[col], kde=True,  linewidth=1)\n",
    "            plt.title(f\"Distribution Plot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "            plt.ylabel(\"Density\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig(filenaam)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkey-patching FunctionTransformer.get_feature_names_out()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# functie om het percentage outliers te berkenen voor een set van kolommen in een dataframe\n",
    "def bereken_percentage_aantal_outliers(df , columns_to_use):\n",
    "    # Initialiseren van het Isolation Forest model\n",
    "    iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "\n",
    "    # Fit het model\n",
    "    iso_forest.fit(df[columns_to_use])\n",
    "    # Voorspellingen\n",
    "    # Het geeft -1 voor outliers en 1 voor inliers\n",
    "    labels = iso_forest.predict(df[columns_to_use])\n",
    "    # Toevoegen van de labels aan het DataFrame om outliers te identificeren\n",
    "    df_intern = df.copy()\n",
    "    df_intern['outlier'] = labels\n",
    "    outliers = df_intern[df_intern['outlier'] == -1]\n",
    "    aantal_outliers = df_intern['outlier'].value_counts()\n",
    "    print(aantal_outliers)\n",
    "    percentage_aantal_outliers = (len(outliers) / len(df_intern)) * 100\n",
    "\n",
    "    return percentage_aantal_outliers\n",
    "\n",
    "\n",
    "# functie om outliers in een kolom te cappen op een percentiel waarde\n",
    "def cap_values(df_input, column, lower_percentile=25, upper_percentile=75):\n",
    "    # voeg code toe om beter de outliers te verwijderen\n",
    "    log(\"Info\", f\"Capping values voor kolom {column} naar lower percentiel {lower_percentile} - upper percentiel {upper_percentile}\")\n",
    "    q1, q3 = np.percentile(df_input[column], [lower_percentile, upper_percentile])  # Calculate the 25th (Q1) and 75th (Q3) percentiles\n",
    "    iqr = q3 - q1  # Calculate the interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower whisker (Q1 - 1.5 * IQR)\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper whisker (Q3 + 1.5 * IQR)\n",
    "\n",
    "    # lower_bound = df[column].quantile(lower_percentile)\n",
    "    # upper_bound = df[column].quantile(upper_percentile)\n",
    "    \n",
    "    # Waarden cappen met behulp van de numpy.where functie\n",
    "    df_output = df_input.copy()\n",
    "    df_output[column] = np.where(df_input[column] < lower_bound, lower_bound, df_input[column])\n",
    "    df_output[column] = np.where(df_input[column] > upper_bound, upper_bound, df_input[column])    \n",
    "    return df_output\n",
    "\n",
    "\n",
    "# hulp klasse om categorische waarden met twee mogelijke waarde naar 0 en 1 om te zetten\n",
    "# try-out om zelf eens een  encoder te schrijven\n",
    "# kan uiteraard eenvoudiger door OneHotEncoding toe te passen\n",
    "\n",
    "class BinaryValueEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, string_zero=\"nul\", string_one=\"een\"):\n",
    "        # Je kunt hier extra initialisatie toevoegen indien nodig\n",
    "        self.string_zero = string_zero\n",
    "        self.string_one = string_one\n",
    "     \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Er is geen fitting nodig voor deze eenvoudige codering\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X wordt aangenomen een pandas DataFrame te zijn\n",
    "        log(\"Info\", f\"BinaryValueEncoder transform opgeroepen voor One_value {self.string_one} en Zero_value {self.string_zero}\")\n",
    "        X = X.copy()  # Kopieer de DataFrame om wijzigingen te voorkomen in het origineel\n",
    "        X = X.applymap(lambda x: 1 if x == self.string_zero else 0)\n",
    "        return X\n",
    "\n",
    "\n",
    "def monkey_patch_get_signature_names_out():\n",
    "    \"\"\"Monkey patch some classes which did not handle get_feature_names_out()\n",
    "       correctly in Scikit-Learn 1.0.*.\"\"\"\n",
    "    from inspect import Signature, signature, Parameter\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import make_pipeline, Pipeline\n",
    "    from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "    default_get_feature_names_out = StandardScaler.get_feature_names_out\n",
    "\n",
    "    if not hasattr(SimpleImputer, \"get_feature_names_out\"):\n",
    "      print(\"Monkey-patching SimpleImputer.get_feature_names_out()\")\n",
    "      SimpleImputer.get_feature_names_out = default_get_feature_names_out\n",
    "\n",
    "    if not hasattr(FunctionTransformer, \"get_feature_names_out\"):\n",
    "        print(\"Monkey-patching FunctionTransformer.get_feature_names_out()\")\n",
    "        orig_init = FunctionTransformer.__init__\n",
    "        orig_sig = signature(orig_init)\n",
    "\n",
    "        def __init__(*args, feature_names_out=None, **kwargs):\n",
    "            orig_sig.bind(*args, **kwargs)\n",
    "            orig_init(*args, **kwargs)\n",
    "            args[0].feature_names_out = feature_names_out\n",
    "\n",
    "        __init__.__signature__ = Signature(\n",
    "            list(signature(orig_init).parameters.values()) + [\n",
    "                Parameter(\"feature_names_out\", Parameter.KEYWORD_ONLY)])\n",
    "\n",
    "        def get_feature_names_out(self, names=None):\n",
    "            if callable(self.feature_names_out):\n",
    "                return self.feature_names_out(self, names)\n",
    "            assert self.feature_names_out == \"one-to-one\"\n",
    "            return default_get_feature_names_out(self, names)\n",
    "\n",
    "        FunctionTransformer.__init__ = __init__\n",
    "        FunctionTransformer.get_feature_names_out = get_feature_names_out\n",
    "\n",
    "\n",
    "    if not hasattr(BinaryValueEncoder, \"get_feature_names_out\"):\n",
    "        print(\"Monkey-patching FunctionTransformer.get_feature_names_out()\")\n",
    "        orig_init = BinaryValueEncoder.__init__\n",
    "        orig_sig = signature(orig_init)\n",
    "\n",
    "        def __init__(*args, feature_names_out=None, **kwargs):\n",
    "            orig_sig.bind(*args, **kwargs)\n",
    "            orig_init(*args, **kwargs)\n",
    "            args[0].feature_names_out = feature_names_out\n",
    "\n",
    "        __init__.__signature__ = Signature(\n",
    "            list(signature(orig_init).parameters.values()) + [\n",
    "                Parameter(\"feature_names_out\", Parameter.KEYWORD_ONLY)])\n",
    "\n",
    "        def get_feature_names_out(self, names=None):\n",
    "            if callable(self.feature_names_out):\n",
    "                return self.feature_names_out(self, names)\n",
    "            assert self.feature_names_out == \"one-to-one\"\n",
    "            return default_get_feature_names_out(self, names)\n",
    "\n",
    "        BinaryValueEncoder.__init__ = __init__\n",
    "        BinaryValueEncoder.get_feature_names_out = get_feature_names_out\n",
    "\n",
    "\n",
    "monkey_patch_get_signature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m10/02/2025 15:12:19 : Info : File data/insurance.csv\n",
      "\u001b[0m10/02/2025 15:12:19 : Info : Check op duplicates na drop \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# data bestand inlezen\n",
    "\n",
    "insurance_data_filename = 'data/insurance.csv'\n",
    "df = pd.read_csv(insurance_data_filename)\n",
    "log_info(f\"File {insurance_data_filename}\")\n",
    "\n",
    "# check op duplicates, indien zo verwijder direct\n",
    "df.drop_duplicates(inplace=True)\n",
    "df_original = df.copy()\n",
    "duplicate_waarden = df.duplicated().sum()\n",
    "log_info(f\"Check op duplicates na drop \\n{duplicate_waarden}\")\n",
    "\n",
    "# behoudt een copie van de orginele data\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1337 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1337 non-null   int64  \n",
      " 1   sex       1337 non-null   object \n",
      " 2   bmi       1337 non-null   float64\n",
      " 3   children  1337 non-null   int64  \n",
      " 4   smoker    1337 non-null   object \n",
      " 5   region    1337 non-null   object \n",
      " 6   charges   1337 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 83.6+ KB\n",
      "\u001b[0m10/02/2025 15:12:19 : Info : df.info : \n",
      "None\n",
      "\u001b[0m10/02/2025 15:12:19 : Info : df.describe : \n",
      "               age          bmi     children       charges\n",
      "count  1337.000000  1337.000000  1337.000000   1337.000000\n",
      "mean     39.222139    30.663452     1.095737  13279.121487\n",
      "std      14.044333     6.100468     1.205571  12110.359656\n",
      "min      18.000000    15.960000     0.000000   1121.873900\n",
      "25%      27.000000    26.290000     0.000000   4746.344000\n",
      "50%      39.000000    30.400000     1.000000   9386.161300\n",
      "75%      51.000000    34.700000     2.000000  16657.717450\n",
      "max      64.000000    53.130000     5.000000  63770.428010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_755d5 thead>tr>th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_755d5_row0_col0, #T_755d5_row1_col0, #T_755d5_row2_col0, #T_755d5_row3_col0, #T_755d5_row4_col0, #T_755d5_row5_col0, #T_755d5_row6_col0 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 5%;\n",
       "  max-width: 50px;\n",
       "  min-width: 20px;\n",
       "}\n",
       "#T_755d5_row0_col1, #T_755d5_row1_col1, #T_755d5_row2_col1, #T_755d5_row3_col1, #T_755d5_row4_col1, #T_755d5_row5_col1, #T_755d5_row6_col1 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 15%;\n",
       "  max-width: 200px;\n",
       "  min-width: 100px;\n",
       "  word-break: break-word;\n",
       "}\n",
       "#T_755d5_row0_col2, #T_755d5_row1_col2, #T_755d5_row2_col2, #T_755d5_row3_col2, #T_755d5_row4_col2, #T_755d5_row5_col2, #T_755d5_row6_col2 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 30%;\n",
       "  min-width: 100px;\n",
       "}\n",
       "#T_755d5_row0_col3, #T_755d5_row1_col3, #T_755d5_row2_col3, #T_755d5_row3_col3, #T_755d5_row4_col3, #T_755d5_row5_col3, #T_755d5_row6_col3 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 25%;\n",
       "  min-width: 100px;\n",
       "}\n",
       "#T_755d5_row0_col4, #T_755d5_row1_col4, #T_755d5_row2_col4, #T_755d5_row3_col4, #T_755d5_row4_col4, #T_755d5_row5_col4, #T_755d5_row6_col4 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 20%;\n",
       "  min-width: 150px;\n",
       "}\n",
       "#T_755d5_row0_col5, #T_755d5_row1_col5, #T_755d5_row2_col5, #T_755d5_row3_col5, #T_755d5_row4_col5, #T_755d5_row5_col5, #T_755d5_row6_col5 {\n",
       "  text-align: left;\n",
       "  font-size: 12px;\n",
       "  vertical-align: middle;\n",
       "  width: 10%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_755d5\">\n",
       "  <caption><strong>Data Frame Summary</strong><br>df<br>Dimensions: 1,337 x 7<br>Duplicates: 0</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_755d5_level0_col0\" class=\"col_heading level0 col0\" >No</th>\n",
       "      <th id=\"T_755d5_level0_col1\" class=\"col_heading level0 col1\" >Variable</th>\n",
       "      <th id=\"T_755d5_level0_col2\" class=\"col_heading level0 col2\" >Stats / Values</th>\n",
       "      <th id=\"T_755d5_level0_col3\" class=\"col_heading level0 col3\" >Freqs / (% of Valid)</th>\n",
       "      <th id=\"T_755d5_level0_col4\" class=\"col_heading level0 col4\" >Graph</th>\n",
       "      <th id=\"T_755d5_level0_col5\" class=\"col_heading level0 col5\" >Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "      <td id=\"T_755d5_row0_col1\" class=\"data row0 col1\" ><strong>age</strong><br>[int64]</td>\n",
       "      <td id=\"T_755d5_row0_col2\" class=\"data row0 col2\" >Mean (sd) : 39.2 (14.0)<br>min < med < max:<br>18.0 < 39.0 < 64.0<br>IQR (CV) : 24.0 (2.8)</td>\n",
       "      <td id=\"T_755d5_row0_col3\" class=\"data row0 col3\" >47 distinct values</td>\n",
       "      <td id=\"T_755d5_row0_col4\" class=\"data row0 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAKQAAABACAYAAACUYNzVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACXklEQVR4nO3cT27aQBiH4W9KCOaPbCEk2HGBSl2w9CF62B4hC07ADdghIQTCiYUx7qJCaSsVYruOfzbvs43GQaOXAY8YuyzLDFDxpe4XAPzu6dYfnXN9M3sueO1TlmVvBcfiQf0zSOdcfzKZfPd9f1zkwofDYeec+0GUyOPWCvns+/44DMO3IAjiPBfd7/fecrkcb7fbZzMjSHzYzY9sM7MgCOLpdPpa4Nr9AmPw4LipgRSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChBSChJS7vxhH9ThM966yINM07ZqZ75wrMrxVk3wLh+n+VEmQURR1kyT5Np/PO51OJ9cBMbNmTnKJVc4fjUbTMAwPHKarKMjT6fTked5gsVjEs9lsl2dsEye5zCqXJImXpunXXq/3wmG6ir9DDofDRzmxWPjI8Hq9Hq9Wq8H5fO5U9eKapHU3NXXeIBQ5Mrzb7Wp78yneTLUqSG4QPk51rloVpPG0jTwk56ptQZoZT9vIQ22uWhnkIymx3+tfLpduDf/X7Mb3T8kg65rkpimz33vdborj+MXMcq2QVe4zywVZ1yQ3UZn93jLbTVXuM8sFWdckmzV3ZS6y3/s/tpuq2GeWC/LqsyeZlVmDbJCfrc6VGe8I8i91ffzhF36gCykECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSkECSl3HxSw3++9vBc9Ho+emVkURd5msxkwlrFX93r6Cb5xtK2GD1U3AAAAAElFTkSuQmCC\"></img></td>\n",
       "      <td id=\"T_755d5_row0_col5\" class=\"data row0 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row1_col0\" class=\"data row1 col0\" >2</td>\n",
       "      <td id=\"T_755d5_row1_col1\" class=\"data row1 col1\" ><strong>sex</strong><br>[object]</td>\n",
       "      <td id=\"T_755d5_row1_col2\" class=\"data row1 col2\" >1. male<br>2. female</td>\n",
       "      <td id=\"T_755d5_row1_col3\" class=\"data row1 col3\" >675 (50.5%)<br>662 (49.5%)</td>\n",
       "      <td id=\"T_755d5_row1_col4\" class=\"data row1 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJsAAAAuCAYAAAA/ZmtKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABN0lEQVR4nO3bwYnDMBRF0a8gwmQjYQwuxkVMsSlC3RhjLZKQjWYxDcR/8YTIPRV8zMWQ4BdaawYoBDO7mdm19yEDerfWnr2PGEmc5/k3pTT1PmQ0tdY9hHAnuM/FlNK0rusz5/zqfcwojuP4KaVM27ZdzYzYPhTNzHLOr2VZHr2PGcyt9wGjufQ+AN+D2CBDbJAhNsgQG2SIDTLEBhligwyxQYbYIENskCE2yBAbZIgNMsQGmWj2/zFg70NGwvPyibXWvZQyGR8DnlJr3c3s3fuOkTB48WPwclJgygcV3mw+vNUcmPI5MOPzYcp3EjM+P6Z8Pvxyd+BPXcgQG2SIDTLEBhligwyxQYbYIENskCE2yBAbZIgNMsQGGWKDDLFBhtggw5TvJJ6VH1M+B2Z8PgxefBi8OPwBCltq31np+ZoAAAAASUVORK5CYII=\"></img></td>\n",
       "      <td id=\"T_755d5_row1_col5\" class=\"data row1 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row2_col0\" class=\"data row2 col0\" >3</td>\n",
       "      <td id=\"T_755d5_row2_col1\" class=\"data row2 col1\" ><strong>bmi</strong><br>[float64]</td>\n",
       "      <td id=\"T_755d5_row2_col2\" class=\"data row2 col2\" >Mean (sd) : 30.7 (6.1)<br>min < med < max:<br>16.0 < 30.4 < 53.1<br>IQR (CV) : 8.4 (5.0)</td>\n",
       "      <td id=\"T_755d5_row2_col3\" class=\"data row2 col3\" >548 distinct values</td>\n",
       "      <td id=\"T_755d5_row2_col4\" class=\"data row2 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAKQAAABACAYAAACUYNzVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACV0lEQVR4nO3bwYraQBzH8f/UdYkKEbHozRco9ODRh+jD9hEq+AS+gTchSMTUYIzpoQvtFnaXjJPmt9nv5z6YwxfDZP7jqqoyQMWnth8A+NtD2w8QmnNuYGaPnssvVVWdQz4P6ulUkM65wXQ6/RbH8cRn/fF4PDjnvhNlezoVpJk9xnE8Wa1W5/F4nNdZmKZptNlsJkmSPJoZQbaka0Gamdl4PM5ns9lPj6WD4A+DWtjUQApBQkonX9m+yrLsm1nsnPNZzg49AIJ8kmVZvyiKr4vFotfr9WptiMzYoYdCkE8ul8tDFEXD5XKZz+fzQ5217NDDIch/jEYjdugtYlMDKQQJKQQJKQQJKQQJKQQJKZKffe6YaYxvt1s/9PPg/5EL8p6ZxqIoorIsv+R5/sPMfL4lomVyQdodM4273W6y3W6H1+u119TDoVmKQZqZ30zj4XDgtOSdY1MDKQQJKQQJKQQJKbKbmveGafMwCDIAps3DIcgAmDYPhyADYtr8fmxqIIUgIYUgIYUgIYUgIYUgIYUgIYUgIYUgIaWxkxouasFHI0FyUQu+mvqH5KIWvDQ6XMFFLdTFpgZSCBJSmIcUwPWHPwiyZVx/eI4gW8b1h+cIUgTXH35jUwMpBAkpBAkpBAkpBAkpBAkpBAkpBAkpr34YZ+pbX9fOwV8MkqlvfV08B3/tH5Kpb3FdPAd/8yybqW99vufgZVnGJva6Z7jig1J93RPkB3Xv6369Xs+SJPnsnDv6/PxLIb8ZZJqmUd1fO51OkZlZlmXRfr8fslZ3rY/z+dzYv+svSFme8aj5M/MAAAAASUVORK5CYII=\"></img></td>\n",
       "      <td id=\"T_755d5_row2_col5\" class=\"data row2 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row3_col0\" class=\"data row3 col0\" >4</td>\n",
       "      <td id=\"T_755d5_row3_col1\" class=\"data row3 col1\" ><strong>children</strong><br>[int64]</td>\n",
       "      <td id=\"T_755d5_row3_col2\" class=\"data row3 col2\" >1. 0<br>2. 1<br>3. 2<br>4. 3<br>5. 4<br>6. 5</td>\n",
       "      <td id=\"T_755d5_row3_col3\" class=\"data row3 col3\" >573 (42.9%)<br>324 (24.2%)<br>240 (18.0%)<br>157 (11.7%)<br>25 (1.9%)<br>18 (1.3%)</td>\n",
       "      <td id=\"T_755d5_row3_col4\" class=\"data row3 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJsAAACKCAYAAAC96ziyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACw0lEQVR4nO3dQU7bUBiF0T9RRJuJowiJZbCALKKL7SKygOwDRXjQUCbpoJTSDoCBfZ9lnzNj9pA+vciRr7K6Xq8FCevWB2A5xEaM2IgRGzGrqtpW1U3rg0zA8/V6vbQ+xJxtbm9vv3Vdt299kNb6vj+vVqvvghvPpuu6/eFwuOx2u6fWh2nl8fHx6/F43D88PNxUldhGsqmq2u12T3d3dz9aH6axbesDzJ0HBGLERozYiBEbMWIjRmzEiI0YsREjNmLERozYiBEbMWIjZlP1+xWb1gdpaen/f8qm7/vz8Xjc18Jfsen7/lxVz63PMWdeC//La+EjWxkpkzLlm81NMzOTHbwYoMzPJAcvBijzNOXBy6KfjufIl7rEiI0YsREjNmLERozYiBEbMWIjRmzEiI0YsREjNmLERozYiJnkumpq52EYk11XWTvNjw0CMdZVxLS42dxYCxVfV1lNLVd0XWU1tWwt1lWTeuolx5e6xIiNGLERIzZixEaM2IgRGzFiI0ZsxIiNGLERIzZixEaM2IiJrqusppYtvq6ymlouGwRirKuIGfJmc2PxrsHWVVZTfGSQdZXVFJ8x5LrKaop3+VKXGLERIzZixEaM2IgRGzFiI0ZsxIiNGLERIzZixEaM2IgZZPBiyMJnDDZ4MWThI14LJ8bghRgPCMT8/zHqo5DR/LOuspBiTOs/66rD4XB5iW6Kvz3KDLyuq17+tpBiNB4QiBEbMWIjRmzEiI0YsREjNmLERozYiBEbMWIjRmzEiI2Y6M8JsWxv11UWUozKa+HEWFcR8/Zmc6sxqtfBi7ELY1t3Xbe/v78vYxfGtq6q2m63P1sfhPnzpS4xYiNGbMSIjRixESM2YsRGjNiIERsxYiNGbMSIjRixESM2YtZVVZfL5UvrgzB/677vz6fTybKK0dkgEGNdRYwHBGLERozYiPkFwEwoLPiIhXAAAAAASUVORK5CYII=\"></img></td>\n",
       "      <td id=\"T_755d5_row3_col5\" class=\"data row3 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row4_col0\" class=\"data row4 col0\" >5</td>\n",
       "      <td id=\"T_755d5_row4_col1\" class=\"data row4 col1\" ><strong>smoker</strong><br>[object]</td>\n",
       "      <td id=\"T_755d5_row4_col2\" class=\"data row4 col2\" >1. no<br>2. yes</td>\n",
       "      <td id=\"T_755d5_row4_col3\" class=\"data row4 col3\" >1,063 (79.5%)<br>274 (20.5%)</td>\n",
       "      <td id=\"T_755d5_row4_col4\" class=\"data row4 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJsAAAAuCAYAAAA/ZmtKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABMklEQVR4nO3bwYnDMBhE4dFiwuYiYQwuxkVssVuEujHGOiQhF+1ha8j8Ar+vAQnyEnDwpN67AIck6S7pFn0RWLx778+ow6dlWX5yznPUBeDTWjtSSr9RwU0553nbtmcp5RVxAXic5/lda533fb9JiolNkkopr3VdHxEXgNU98vCvyMNxLcQGG2KDDbHBhthgQ2ywITbYEBtsiA02xAYbYoMNscGG2GBDbLAhNthM0v+LddEXwWeN8BlPrbWj1jor+MU6fF5r7ZD0jjqfwcu1hA5eElM+uIzwyxb6bYNP+JQvel4Gn9Ap3wjzMviMMOXjKfgi+FMXNsQGG2KDDbHBhthgQ2ywITbYEBtsiA02xAYbYoMNscGG2GBDbLAhNtiETvlGmJfBJ3zKFz0vgw+DF9j8AQpbat+srJxBAAAAAElFTkSuQmCC\"></img></td>\n",
       "      <td id=\"T_755d5_row4_col5\" class=\"data row4 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row5_col0\" class=\"data row5 col0\" >6</td>\n",
       "      <td id=\"T_755d5_row5_col1\" class=\"data row5 col1\" ><strong>region</strong><br>[object]</td>\n",
       "      <td id=\"T_755d5_row5_col2\" class=\"data row5 col2\" >1. southeast<br>2. southwest<br>3. northwest<br>4. northeast</td>\n",
       "      <td id=\"T_755d5_row5_col3\" class=\"data row5 col3\" >364 (27.2%)<br>325 (24.3%)<br>324 (24.2%)<br>324 (24.2%)</td>\n",
       "      <td id=\"T_755d5_row5_col4\" class=\"data row5 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAJsAAABcCAYAAAB5jMeAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABxUlEQVR4nO3bTYrbQBSF0acgmvREwhi8GC8ii80itBtjXIN00xNlkHHSPwm3qp1zVvAGHzYSutO+7wUJX3ofwP9DbMRMVfVYVQ+9D3mDl33fn3ofwcfNx+Px27Ish96HvKa1dp2m6bvgPq95WZbD+Xx+Wtf1ufcxv3O73b5u23a4XC4PVSW2T2quqlrX9fl0Ov3ofcwrHnsfwN/xgECM2IgRGzFiI0ZsxIiNGLERIzZixEaM2IgRGzFiI0ZsxMxVvz7h6X3In4x+H28zt9au27YdavBPeFpr16p66X0HH+ezcGImUz5SPCAQM/LfqL/NOzPsusqa6v4Mua6yprpPI6+rhn4Vw/t5QCBGbMSIjRixESM2YsRGjNiIERsxYiNGbMSIjRixESM2YsRGzJBTvtHu4d8Ydspnund/bBCIMeUjxi8bMdZVxFhXEWNdRYyXusSIjRixESM2YsRGjNiIERsxYiNGbMSIjRixESM2YsRGjNiIsa4ixrqKGBsEYqyriPHLRox1FTHWVcRYVxHjpS4xYiNGbMSIjRixESM2YsRGjNiIERsxYiNGbMSIjRixESM2YqyriLGuIsYGgRjrKmI8IBDzEyec2Ln5AaEYAAAAAElFTkSuQmCC\"></img></td>\n",
       "      <td id=\"T_755d5_row5_col5\" class=\"data row5 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_755d5_row6_col0\" class=\"data row6 col0\" >7</td>\n",
       "      <td id=\"T_755d5_row6_col1\" class=\"data row6 col1\" ><strong>charges</strong><br>[float64]</td>\n",
       "      <td id=\"T_755d5_row6_col2\" class=\"data row6 col2\" >Mean (sd) : 13279.1 (12110.4)<br>min < med < max:<br>1121.9 < 9386.2 < 63770.4<br>IQR (CV) : 11911.4 (1.1)</td>\n",
       "      <td id=\"T_755d5_row6_col3\" class=\"data row6 col3\" >1,337 distinct values</td>\n",
       "      <td id=\"T_755d5_row6_col4\" class=\"data row6 col4\" ><img src = \"data:image/png;base64, iVBORw0KGgoAAAANSUhEUgAAAKQAAABACAYAAACUYNzVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACg0lEQVR4nO3cz6raQBSA8XPqH6LSCeJFd75AoQuXbvoG92G77a6CvoBv4EaEECNarRrTjRfacuttxlqPyffbygxZfCQzZohmWSaAFe/ufQHAz6qXflTVhojUPefeZ1m29RyLkvpjkKra6HQ6z865ts/Eq9UqVtXPRIk8Lt0h68659nA43IZhuMszaZIkwXg8bkdRVBcRgsRfu/jIFhEJw3DX7Xa/eczd8BiDkmNTA1MIEqYQJEwhSJhCkDCFIGEKQcIUgoQpBAlTCBKmECRMIUiY8ubhCl9pmtZExKmqz3DOUpbUTYLcbDa1w+Hwsd/vVyqVSq6jayKcpSyzmwS53++rQRA0B4PBrtfrxXnGcpay3G72yBYRabVanKVELmxqYApBwhSChCkECVMIEqYQJEwhSJhCkDCFIGEKQcIUgoQpBAlTCBKmECRMIUiYQpAwhSBhCkHCFIKEKQQJUwgSphAkTCFImEKQMIUgYQpBwpSbfkrFF19OKy9zQfLltHIzFyRfTis3c0G+4Mtp5cSmBqaYvUP6YkP02AoVJBuix1eoINkQPb5CBfniHhsiVW2ISN1zOEuFs0IG+b+paqPT6Tw759o+45fL5VpVv4hI7mWGFCxmgvw36s659nA43IZhmCuq+Xz+fjKZfOr3+0+sewnyF1fs0N3pdKqFYRjnXSrEcdy4Zt07Go26URQ9qeoq3yWLiMG7K0GeXbNDPxwOQZqmH3a73VcR8Vm7eq17i/ivAkGeXbNDn81m7el02jwej5VbXd9rivivAkH+xudOFcfxXV9XFuk165tBJkkS5J10vV4HIiKbzSZYLBZNxtobmyRJkKZpVfzfal3je5Zlry4xfgC17GxL7dOXxwAAAABJRU5ErkJggg==\"></img></td>\n",
       "      <td id=\"T_755d5_row6_col5\" class=\"data row6 col5\" >0<br>(0.0%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22ad1f58050>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enkele eenvoudige controles\n",
    "log_info(f\"df.info : \\n{df.info()}\")\n",
    "log_info(f\"df.describe : \\n{df.describe()}\")\n",
    "\n",
    "# geen nulwaarden \n",
    "from summarytools import dfSummary\n",
    "dfSummary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drie categorische features: smoking, region en sex\n",
    "# vier numerische features waaronder de target variabele \"charges\"\n",
    "# maak de datasets aan \n",
    "\n",
    "df_cat_col = ['smoker','region','sex']\n",
    "df_num_col = ['age', 'bmi','children']\n",
    "df_label_col = ['charges']\n",
    "\n",
    "# zijn er nominaal categorische variabelen en één ordinal categorische waarden?\n",
    "df_cat_nom_col = ['smoker','region']\n",
    "df_cat_ord_col = list(set(df_cat_col) - set(df_cat_nom_col))\n",
    "\n",
    "df_num = df[df_num_col]\n",
    "df_cat = df[df_cat_col]\n",
    "df_label = df[df_label_col]\n",
    "df_cat_nom = df[df_cat_nom_col]\n",
    "df_cat_ord = df[df_cat_ord_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoker  region     sex   \n",
      "no      southwest  female    141\n",
      "        southeast  female    139\n",
      "        northwest  female    135\n",
      "        southeast  male      134\n",
      "        northeast  female    132\n",
      "        northwest  male      131\n",
      "        southwest  male      126\n",
      "        northeast  male      125\n",
      "yes     southeast  male       55\n",
      "        northeast  male       38\n",
      "        southwest  male       37\n",
      "        southeast  female     36\n",
      "        northwest  male       29\n",
      "                   female     29\n",
      "        northeast  female     29\n",
      "        southwest  female     21\n",
      "Name: count, dtype: int64\n",
      "\u001b[0m10/02/2025 15:12:20 : Info : Check op nulwaarden \n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# korte analyze van de categorische variabelen\n",
    "print(df_cat.value_counts())\n",
    "\n",
    "# check op nullen\n",
    "nul_waarden = df.isnull().sum()\n",
    "log_info(f\"Check op nulwaarden \\n{nul_waarden}\")\n",
    "# geen nullen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_num_col,\"Boxplot en histogram van de numerische waarden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_label_col,\"Boxplot en histogram van de target value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright')\n",
    "        plt.title(f\"Count Plot of {col}\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische features countplot\")\n",
    "    plt.show()\n",
    "    log_info(\"Check van categorische features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright', hue='smoker')\n",
    "        plt.title(f\"Count Plot of {col} (Hue: Smoker)\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische variabelen tov smoker\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.pairplot(df, hue='smoker',  kind='reg')\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Numerische features onderlinge scatter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print de correlation nog af tussen de numerische waarden\n",
    "\n",
    "if plot_graphs:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    sns.heatmap(df[df_num_col].corr(), annot=True, cmap='Reds')\n",
    "    save_fig(\"Numerische features correlatie\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier\n",
      " 1    1074\n",
      "-1     263\n",
      "Name: count, dtype: int64\n",
      "19.670905011219148\n",
      "\u001b[0m10/02/2025 15:12:52 : Info : Check op de outliers in kolom ['bmi'] : 19.670905011219148\n",
      "\u001b[0m10/02/2025 15:13:01 : Info : Capping values voor kolom bmi naar lower percentiel 25 - upper percentiel 75\n",
      "outlier\n",
      " 1    1030\n",
      "-1     307\n",
      "Name: count, dtype: int64\n",
      "22.961854899027674\n",
      "\u001b[0m10/02/2025 15:13:16 : Info : Check op de outliers in kolom [bmi, charges] na capping op kolom [bmi]  : 22.961854899027674\n",
      "\u001b[0m10/02/2025 15:13:17 : Info : Capping wordt niet toegepast op de dataset\n"
     ]
    }
   ],
   "source": [
    "def verwijder_outliers(df_input, df_input_col):\n",
    "    # Bereken de outliers\n",
    "    percentage_aantal_outliers = bereken_percentage_aantal_outliers(df_input, df_input_col)\n",
    "    print(percentage_aantal_outliers)\n",
    "    log_info(f\"Check op de outliers in kolom {df_input_col} : {percentage_aantal_outliers}\")\n",
    "\n",
    "    df_output = df_input.copy()\n",
    "    for col in df_input_col:\n",
    "        df_output = cap_values(df_output, col)    \n",
    "\n",
    "    percentage_aantal_outliers = bereken_percentage_aantal_outliers(df_output, df_input_col)\n",
    "    print(percentage_aantal_outliers)\n",
    "    # plot_boxplot(df, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "    log_info(f\"Check op de outliers in kolom [bmi, charges] na capping op kolom [bmi]  : {percentage_aantal_outliers}\")\n",
    "    log_info(\"Capping wordt niet toegepast op de dataset\")\n",
    "\n",
    "    return df_output\n",
    "\n",
    "plot_boxplot(df_original, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "df_zonder_outliers = verwijder_outliers(df_original,['bmi'])\n",
    "plot_boxplot(df_zonder_outliers, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preparation\n",
    "# standard scaler op de numerische waarden, min-max scaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "\n",
    "#set_matplotlib_closeV_encoder = BinaryValueEncoder(\"male\",\"female\")\n",
    "#set_matplotlib_smoking_encoder = BinaryValueEncoder(\"yes\",\"no\")\n",
    "# bv_encoder = PredefinedBinaryCategoricalEncoder(positive_class='female')\n",
    "\n",
    "male_female_transformer = Pipeline(steps=[\n",
    "     #('male_female_encoder', BinaryValueEncoder(\"male\",\"female\"))\n",
    "    ('male_female_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "smoking_transformer = Pipeline(steps=[\n",
    "    #('smoking_encoder', BinaryValueEncoder(\"yes\",\"no\"))\n",
    "    ('smoking_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "regio_transformer = Pipeline(steps=[\n",
    "    ('regio', OneHotEncoder(drop='first', handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, df_num_col),\n",
    "    (\"male_female\", male_female_transformer, ['sex']), \n",
    "    (\"smoker\", smoking_transformer, ['smoker']), \n",
    "    (\"regio\", regio_transformer, ['region'])],\n",
    "     remainder='passthrough')\n",
    "\n",
    "df_features = df_original.drop(['charges'], axis= 1)\n",
    "np_prepared =  preprocessing.fit_transform(df_features)\n",
    "\n",
    "# really hacking !!! get_feature_names werkt nog niet correct !!! not used now\n",
    "df_prepared_col = ['age', 'bmi','children','sex','smoker','northeast','northwest','southeast','southwest']\n",
    "\n",
    "df_prepared = pd.DataFrame(\n",
    "    np_prepared,\n",
    "    #columns=preprocessing.get_feature_names_out(),\n",
    "    columns = [name.split('__')[-1] for name in preprocessing.get_feature_names_out()],\n",
    "    #columns = df_prepared_col,\n",
    "    index=df_original.index)\n",
    "\n",
    "df_prepared.head()\n",
    "\n",
    "plot_boxplot(df_prepared,df_num_col,\"Boxplot van numerische waarden na standard scaling\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excute_regression_models(X_train, X_test, y_train,y_test):\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Lasso': Lasso(alpha=0.1) ,\n",
    "        'Ridge': Ridge(alpha=0.01) ,\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "        'XGBRegressor': XGBRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        # Cross validation\n",
    "        mean_rmse = np.sqrt(-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "        mean_r2 = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        results.append([name, mean_rmse, mean_r2, test_rmse, test_r2, test_mape])\n",
    "    df = pd.DataFrame(results, columns=['model', 'mean_rmse', 'mean_r2', 'test_rmse', 'test_r2', 'test_mape\"'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m10/02/2025 15:16:19 : Info : Train_test_split met stratefy = charges_cat\n",
      "               model    mean_rmse   mean_r2    test_rmse   test_r2  test_mape\"\n",
      "0  Linear Regression  6126.274424  0.725757  5956.342894  0.806929    0.413968\n",
      "1              Lasso  6126.263748  0.725758  5956.469620  0.806920    0.413981\n",
      "2              Ridge  6126.264010  0.725759  5956.496425  0.806919    0.413992\n",
      "3      Random Forest  4956.997994  0.820776  4713.964344  0.879071    0.376728\n",
      "4  Gradient Boosting  4770.832863  0.834189  4268.715369  0.900836    0.315129\n",
      "5      Decision Tree  6700.088280  0.669360  5850.383924  0.813737    0.348618\n",
      "6       XGBRegressor  5267.275726  0.797652  5058.168538  0.860766    0.418510\n",
      "\u001b[0m10/02/2025 15:16:25 : Info : Regresison models with no stratefy\n",
      "\u001b[0m10/02/2025 15:16:25 : Info :                model    mean_rmse   mean_r2    test_rmse   test_r2  test_mape\"\n",
      "0  Linear Regression  6126.274424  0.725757  5956.342894  0.806929    0.413968\n",
      "1              Lasso  6126.263748  0.725758  5956.469620  0.806920    0.413981\n",
      "2              Ridge  6126.264010  0.725759  5956.496425  0.806919    0.413992\n",
      "3      Random Forest  4956.997994  0.820776  4713.964344  0.879071    0.376728\n",
      "4  Gradient Boosting  4770.832863  0.834189  4268.715369  0.900836    0.315129\n",
      "5      Decision Tree  6700.088280  0.669360  5850.383924  0.813737    0.348618\n",
      "6       XGBRegressor  5267.275726  0.797652  5058.168538  0.860766    0.418510\n"
     ]
    }
   ],
   "source": [
    "X = df_prepared.copy()\n",
    "y = df_original['charges']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "log_info(\"Train_test_split met stratefy = charges_cat\")\n",
    "\n",
    "resultaat_eenvoudig = excute_regression_models(X_train, X_test, y_train, y_test)\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"Regresison models with no stratefy\")\n",
    "log_info(resultaat_eenvoudig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set opsplitsen\n",
    "# voorlopig via een aanvoudig train_test_split, nadien gaan we dit doen op het histogram van de charges\n",
    "\n",
    "X = df_original.drop(['charges_cat'],axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "log_info(\"Train_test_split met stratefy = charges_cat\")\n",
    "\n",
    "resultaat_eenvoudig = excute_regression_models(X_train, X_test, y_train, y_test)\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"Regresison models with no stratefy\")\n",
    "log_info(resultaat_eenvoudig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# opdelen train - test - set\n",
    "\n",
    "# gebruik maken van stratefy en op basis van de categorisatie van de charges\n",
    "# om ervoor te zorgen dat in de train - test split zelfde verhoudingen voorkomen\n",
    "\n",
    "df_prepared[\"charges_cat\"] = pd.cut(df[\"charges\"], bins=[0, 20000,30000, np.inf], labels=[1, 2, 3])\n",
    "log_info(\"extra feature engineering: charges omzetten naar categories : bins=[0, 20000,30000, np.inf\")\n",
    "df.head()\n",
    "X = df_prepared.drop(['charges_cat'],axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "#y = df['charges']\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df_prepared[\"charges_cat\"] , test_size=0.4, random_state=42)\n",
    "# log_info(\"Train_test_split met stratefy = charges_cat\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "log_info(\"Train_test_split met stratefy = charges_cat\")\n",
    "\n",
    "\n",
    "excute_regression_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpele linear regression \n",
    "\n",
    "linreg_model = LinearRegression()\n",
    "linreg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'R-squared (R²): {r2}')\n",
    "\n",
    "print(f\"We zitten er gemiddeld {mape*100:.2f}% naast met onze voorspellingen.\")\n",
    "log_info(f\"Linear regression met MSE {mse:.2f}, RMSE {rmse:.2f}, R² {r2:.2f}, gemiddelde afwijking {mape*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Perfect prediction line\n",
    "plt.title('Predicted vs Actual Charges')\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge Regression\n",
    "\n",
    "ridge = Ridge(alpha=0.01)  \n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"\\nRidge Regression Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_ridge}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_ridge}\")\n",
    "print(f\"R-squared (R²): {r2_ridge}\")\n",
    "mape_ridge = mean_absolute_percentage_error(y_test, y_pred_ridge)\n",
    "print(f\"We zitten er gemiddeld {mape_ridge*100:.2f}% naast met onze voorspellingen.\")\n",
    "\n",
    "log_info(f\"Rdige regression met MSE {mse_ridge:.2f}, RMSE {rmse_ridge:.2f}, R² {r2_ridge:.2f}, gemiddelde afwijking {mape_ridge*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_ridge, color='blue', alpha=0.6)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Perfect prediction line\n",
    "plt.title('Predicted vs Actual Charges')\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)  \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "mape_lasso = mean_absolute_percentage_error(y_test, y_pred_lasso)\n",
    "print(f\"We zitten er gemiddeld {mape_lasso*100:.2f}% naast met onze voorspellingen.\")\n",
    "\n",
    "print(\"Lasso Regression Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lasso}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
    "print(f\"R-squared (R²): {r2_lasso}\")\n",
    "log_info(f\"Lasso regression met MSE {mse_lasso:.2f}, RMSE {rmse_lasso:.2f}, R² {r2_lasso:.2f}, gemiddelde afwijking {mape_lasso*100:.2f}%\")\n",
    "log_info_write_to_file(\"LinReg_logging.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(columns=['charges'])\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.1) ,\n",
    "    'Ridge': Ridge(alpha=0.01) ,\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "    'XGBRegressor': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    # Cross validation\n",
    "    mean_rmse = np.sqrt(-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "    mean_r2 = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    test_r2 = r2_score(y_test, y_pred)\n",
    "    test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    results.append([name, mean_rmse, mean_r2, test_rmse, test_r2])\n",
    "df = pd.DataFrame(results, columns=['model', 'mean_rmse', 'mean_r2', 'test_rmse', 'test_r2'])\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
