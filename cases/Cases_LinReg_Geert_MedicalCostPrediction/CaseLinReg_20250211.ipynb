{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook Linear Regression Case\n",
    "Oefening Data Scientist \n",
    "Geert Vandezande\n",
    "\n",
    "Doel:\n",
    "- Supervised Learning toepassen\n",
    "- EDA uitvoeren op een dataset\n",
    "- Lineair Regression toepassen op de data: de target is beter doen dan r² = 80% nauwkeurigheid die in de meeste uitwerkingen zit...\n",
    "- Ook door andere vormen van regressie toe te passen, het doel is om r² zo goed mogelijk te krijgen\n",
    "\n",
    "==> Resultaat: r² = 86% en 27% fout marge \n",
    "\n",
    "\n",
    "Extra:\n",
    "- er wordt logging voorzien voor en na de belangrijke stappen (zie LinReg_logging.log). Hiermee kunnen de stappen en de resultaten opgevolgd worden. Dit wordt in de LinReg_logging weg geschreven\n",
    "- we hebben een aantal herbruikbare code-blokken in een functie gestoken\n",
    "- een aparte class gemaakt voor BinaryValueEncoders om eens te proberen (kan uiteraard met de OneHotEncoder)\n",
    "- we hebben een functie geschreven om snel een reeks van modellen te kunnen evalueren, zowel zonder pipelining als met pipelining\n",
    "\n",
    "Dataset: \n",
    "- More info: see kaggle https://www.kaggle.com/datasets/mirichoi0218/insurance/data\n",
    "\n",
    "Metadata :\n",
    "- age: age of primary beneficiary\n",
    "- sex: insurance contractor gender, female, male\n",
    "- bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "- children: Number of children covered by health insurance / Number of dependents\n",
    "- smoker: Smoking\n",
    "- region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "- charges: Individual medical costs billed by health insurance\n",
    "\n",
    "\n",
    "Volgorde van activiteiten in deze notebook: (cfr Datacamp \"preparing data for modelling)\n",
    "- data inlezen\n",
    "- data bekijken, visueel en numerisch\n",
    "- data summarizen via summarytools \n",
    "- missing en duplicated data oplossen \n",
    "- incorrect types controleren\n",
    "- numerische waarde standardizeren\n",
    "- categorische varaiabelen processen\n",
    "- feature engineering checken\n",
    "- linear, ridge, lasso, gradient boost, random forest,...  modellen uitvoeren\n",
    "- alle modellen toegepast op 2 situaties voor stratefy\n",
    "    - Train_test_split zonder stratify\n",
    "    - Train_test_split met stratefy op basis van de categorisatie van de charges (target v) (omdat er skewness is op charges )\n",
    "\n",
    "- zowel met pipelining als zonder pipelining uitgewerkt\n",
    "- voor het beste model (XGSBoost) gaan we nog een Hyperparameter tuning uitvoeren\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import van de diverse modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Machine learning algorithm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import  mean_absolute_percentage_error\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# system utils\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from colorama import Fore, Back, Style\n",
    "import sys\n",
    "import os\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra code snippits die doorheen de notebook gebruikt worden:\n",
    "\n",
    "save_fig: na generatie van een image kan de image naar file geschreven worden in de images/.. directory. Geef steeds een zinvolle naam\n",
    "\n",
    "read_JSON: om eenvoudig een JSON in te lezen\n",
    "\n",
    "log_info:\n",
    "- logging functie om doorheen de notebooks de status naar file te kunnen schrijven. \n",
    "- de logstatements worden tijdens de uitvoering van de code bewaard in een list. Die kan tussentijds naar het scherm geprint worden of naar een file\n",
    "- log_info_write_to_file: schrijf de loginformatie naar file \n",
    "- log_info_print_on_screen: print alle loginfo naar het scherm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkele extra code snippets gebruikt doorheen de oefening\n",
    "\n",
    "plot_graphs = False\n",
    "\n",
    "# schrijf een visual naar file\n",
    "IMAGES_PATH = Path() / \"images\" \n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "# functies om te loggen naar file\n",
    "# Lezen van de JSON-file\n",
    "log_info_lijst = []\n",
    "\n",
    "def read_JSON(file_path_read):\n",
    "    with open(file_path_read, 'r') as file:\n",
    "        files_from_json = json.load(file)\n",
    "    return files_from_json\n",
    "\n",
    "def log(log_code=\"INFO\", boodschap=\"euh geen boodschap????\"):\n",
    "    global log_info_lijst\n",
    "    now = datetime.datetime.now()\n",
    "    formatted_date = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    log_message = f\"{Style.RESET_ALL}{formatted_date} : {log_code} : {boodschap}\"\n",
    "    log_info_lijst.append(log_message)\n",
    "    print(log_message)\n",
    "    return\n",
    "\n",
    "def log_info(boodschap):\n",
    "    log(\"Info\",boodschap)\n",
    "\n",
    "def log_info_write_to_file(filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        for string in log_info_lijst:\n",
    "            file.write(string + '\\n')  # Voeg een nieuwe regel toe na elke string\n",
    "    return\n",
    "\n",
    "def log_info_print_on_screen():\n",
    "    for boodschap in log_info_lijst:\n",
    "        print(boodschap)    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak een boxplot van een kolommen\n",
    "# df_num_col is een list van de kolomnamen die geplot worden\n",
    "\n",
    "def plot_boxplot(df, df_col, filenaam):\n",
    "    if plot_graphs:\n",
    "        # boxplot van de numerische waarden\n",
    "        sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "        plt.figure(figsize=(15, 15)) \n",
    "        for i, col in enumerate(df_col):\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 1)\n",
    "            sns.boxplot(x=df[col], orient='h', linewidth=1.5)\n",
    "            plt.title(f\"Boxplot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "\n",
    "            plt.subplot(len(df_col), 2, 2 * i + 2)\n",
    "            sns.histplot(df[col], kde=True,  linewidth=1)\n",
    "            plt.title(f\"Distribution Plot of {col}\", fontsize=12, fontweight=\"bold\")\n",
    "            plt.xlabel(col, fontsize=10)\n",
    "            plt.ylabel(\"Density\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_fig(filenaam)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# functie om het percentage outliers te berkenen voor een set van kolommen in een dataframe\n",
    "def bereken_percentage_aantal_outliers(df , columns_to_use):\n",
    "    # Initialiseren van het Isolation Forest model\n",
    "    iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "\n",
    "    # Fit het model\n",
    "    iso_forest.fit(df[columns_to_use])\n",
    "    # Voorspellingen\n",
    "    # Het geeft -1 voor outliers en 1 voor inliers\n",
    "    labels = iso_forest.predict(df[columns_to_use])\n",
    "    # Toevoegen van de labels aan het DataFrame om outliers te identificeren\n",
    "    df_intern = df.copy()\n",
    "    df_intern['outlier'] = labels\n",
    "    outliers = df_intern[df_intern['outlier'] == -1]\n",
    "    aantal_outliers = df_intern['outlier'].value_counts()\n",
    "    print(aantal_outliers)\n",
    "    percentage_aantal_outliers = (len(outliers) / len(df_intern)) * 100\n",
    "\n",
    "    return percentage_aantal_outliers\n",
    "\n",
    "\n",
    "# functie om outliers in een kolom te cappen op een percentiel waarde\n",
    "def cap_values(df_input, column, lower_percentile=25, upper_percentile=75):\n",
    "    # voeg code toe om beter de outliers te verwijderen\n",
    "    log(\"Info\", f\"Capping values voor kolom {column} naar lower percentiel {lower_percentile} - upper percentiel {upper_percentile}\")\n",
    "    q1, q3 = np.percentile(df_input[column], [lower_percentile, upper_percentile])  # Calculate the 25th (Q1) and 75th (Q3) percentiles\n",
    "    iqr = q3 - q1  # Calculate the interquartile range (IQR)\n",
    "    lower_bound = q1 - 1.5 * iqr  # Calculate lower whisker (Q1 - 1.5 * IQR)\n",
    "    upper_bound = q3 + 1.5 * iqr  # Calculate upper whisker (Q3 + 1.5 * IQR)\n",
    "\n",
    "    # lower_bound = df[column].quantile(lower_percentile)\n",
    "    # upper_bound = df[column].quantile(upper_percentile)\n",
    "    \n",
    "    # Waarden cappen met behulp van de numpy.where functie\n",
    "    df_output = df_input.copy()\n",
    "    df_output[column] = np.where(df_input[column] < lower_bound, lower_bound, df_input[column])\n",
    "    df_output[column] = np.where(df_input[column] > upper_bound, upper_bound, df_input[column])    \n",
    "    return df_output\n",
    "\n",
    "\n",
    "# hulp klasse om categorische waarden met twee mogelijke waarde naar 0 en 1 om te zetten\n",
    "# try-out om zelf eens een  encoder te schrijven\n",
    "# kan uiteraard eenvoudiger door OneHotEncoding toe te passen\n",
    "\n",
    "class BinaryValueEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, string_zero=\"nul\", string_one=\"een\"):\n",
    "        # Je kunt hier extra initialisatie toevoegen indien nodig\n",
    "        self.string_zero = string_zero\n",
    "        self.string_one = string_one\n",
    "     \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Er is geen fitting nodig voor deze eenvoudige codering\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # X wordt aangenomen een pandas DataFrame te zijn\n",
    "        log(\"Info\", f\"BinaryValueEncoder transform opgeroepen voor One_value {self.string_one} en Zero_value {self.string_zero}\")\n",
    "        X = X.copy()  # Kopieer de DataFrame om wijzigingen te voorkomen in het origineel\n",
    "        X = X.applymap(lambda x: 1 if x == self.string_zero else 0)\n",
    "        return X\n",
    "\n",
    "\n",
    "def monkey_patch_get_signature_names_out():\n",
    "    \"\"\"Monkey patch some classes which did not handle get_feature_names_out()\n",
    "       correctly in Scikit-Learn 1.0.*.\"\"\"\n",
    "    from inspect import Signature, signature, Parameter\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.pipeline import make_pipeline, Pipeline\n",
    "    from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "    default_get_feature_names_out = StandardScaler.get_feature_names_out\n",
    "\n",
    "    if not hasattr(SimpleImputer, \"get_feature_names_out\"):\n",
    "      print(\"Monkey-patching SimpleImputer.get_feature_names_out()\")\n",
    "      SimpleImputer.get_feature_names_out = default_get_feature_names_out\n",
    "\n",
    "    if not hasattr(FunctionTransformer, \"get_feature_names_out\"):\n",
    "        print(\"Monkey-patching FunctionTransformer.get_feature_names_out()\")\n",
    "        orig_init = FunctionTransformer.__init__\n",
    "        orig_sig = signature(orig_init)\n",
    "\n",
    "        def __init__(*args, feature_names_out=None, **kwargs):\n",
    "            orig_sig.bind(*args, **kwargs)\n",
    "            orig_init(*args, **kwargs)\n",
    "            args[0].feature_names_out = feature_names_out\n",
    "\n",
    "        __init__.__signature__ = Signature(\n",
    "            list(signature(orig_init).parameters.values()) + [\n",
    "                Parameter(\"feature_names_out\", Parameter.KEYWORD_ONLY)])\n",
    "\n",
    "        def get_feature_names_out(self, names=None):\n",
    "            if callable(self.feature_names_out):\n",
    "                return self.feature_names_out(self, names)\n",
    "            assert self.feature_names_out == \"one-to-one\"\n",
    "            return default_get_feature_names_out(self, names)\n",
    "\n",
    "        FunctionTransformer.__init__ = __init__\n",
    "        FunctionTransformer.get_feature_names_out = get_feature_names_out\n",
    "\n",
    "\n",
    "    if not hasattr(BinaryValueEncoder, \"get_feature_names_out\"):\n",
    "        print(\"Monkey-patching FunctionTransformer.get_feature_names_out()\")\n",
    "        orig_init = BinaryValueEncoder.__init__\n",
    "        orig_sig = signature(orig_init)\n",
    "\n",
    "        def __init__(*args, feature_names_out=None, **kwargs):\n",
    "            orig_sig.bind(*args, **kwargs)\n",
    "            orig_init(*args, **kwargs)\n",
    "            args[0].feature_names_out = feature_names_out\n",
    "\n",
    "        __init__.__signature__ = Signature(\n",
    "            list(signature(orig_init).parameters.values()) + [\n",
    "                Parameter(\"feature_names_out\", Parameter.KEYWORD_ONLY)])\n",
    "\n",
    "        def get_feature_names_out(self, names=None):\n",
    "            if callable(self.feature_names_out):\n",
    "                return self.feature_names_out(self, names)\n",
    "            assert self.feature_names_out == \"one-to-one\"\n",
    "            return default_get_feature_names_out(self, names)\n",
    "\n",
    "        BinaryValueEncoder.__init__ = __init__\n",
    "        BinaryValueEncoder.get_feature_names_out = get_feature_names_out\n",
    "\n",
    "\n",
    "monkey_patch_get_signature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data bestand inlezen\n",
    "\n",
    "insurance_data_filename = 'data/insurance.csv'\n",
    "df = pd.read_csv(insurance_data_filename)\n",
    "log_info(f\"File {insurance_data_filename}\")\n",
    "\n",
    "# check op duplicates, indien zo verwijder direct\n",
    "df.drop_duplicates(inplace=True)\n",
    "df_original = df.copy()\n",
    "duplicate_waarden = df.duplicated().sum()\n",
    "log_info(f\"Check op duplicates na drop \\n{duplicate_waarden}\")\n",
    "\n",
    "# behoudt een copie van de orginele data\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enkele eenvoudige controles\n",
    "log_info(f\"df.info : \\n{df.info()}\")\n",
    "log_info(f\"df.describe : \\n{df.describe()}\")\n",
    "\n",
    "# geen nulwaarden \n",
    "from summarytools import dfSummary\n",
    "dfSummary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drie categorische features: smoking, region en sex\n",
    "# vier numerische features waaronder de target variabele \"charges\"\n",
    "# maak de datasets aan \n",
    "\n",
    "df_cat_col = ['smoker','region','sex']\n",
    "df_num_col = ['age', 'bmi','children']\n",
    "df_label_col = ['charges']\n",
    "\n",
    "# zijn er nominaal categorische variabelen en één ordinal categorische waarden?\n",
    "df_cat_nom_col = ['smoker','region']\n",
    "df_cat_ord_col = list(set(df_cat_col) - set(df_cat_nom_col))\n",
    "\n",
    "df_num = df[df_num_col]\n",
    "df_cat = df[df_cat_col]\n",
    "df_label = df[df_label_col]\n",
    "df_cat_nom = df[df_cat_nom_col]\n",
    "df_cat_ord = df[df_cat_ord_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# korte analyze van de categorische variabelen\n",
    "print(df_cat.value_counts())\n",
    "\n",
    "# check op nullen\n",
    "nul_waarden = df.isnull().sum()\n",
    "log_info(f\"Check op nulwaarden \\n{nul_waarden}\")\n",
    "# geen nullen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_num_col,\"Boxplot en histogram van de numerische waarden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df, df_label_col,\"Boxplot en histogram van de target value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright')\n",
    "        plt.title(f\"Count Plot of {col}\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische features countplot\")\n",
    "    plt.show()\n",
    "    log_info(\"Check van categorische features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    plt.figure(figsize=(15, len(df_cat_col) * 2))  \n",
    "\n",
    "    for i, col in enumerate(df_cat_col):\n",
    "        plt.subplot(1, len(df_cat_col), i + 1)\n",
    "        sns.countplot(x=col, data=df, palette='bright', hue='smoker')\n",
    "        plt.title(f\"Count Plot of {col} (Hue: Smoker)\", fontsize=14, fontweight=\"bold\")\n",
    "        plt.xlabel(col, fontsize=12)\n",
    "        plt.ylabel(\"Count\", fontsize=12)\n",
    "        plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Categorische variabelen tov smoker\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_graphs:\n",
    "    sns.pairplot(df, hue='smoker',  kind='reg')\n",
    "    plt.tight_layout()\n",
    "    save_fig(\"Numerische features onderlinge scatter\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print de correlation nog af tussen de numerische waarden\n",
    "\n",
    "if plot_graphs:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_theme(style=\"whitegrid\", palette=\"bright\")\n",
    "    sns.heatmap(df[df_num_col].corr(), annot=True, cmap='Reds')\n",
    "    save_fig(\"Numerische features correlatie\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "Dataset = df.copy()\n",
    "Dataset['sex'] = Dataset['sex'].replace(['male','female'],[0,1])\n",
    "Dataset['smoker'] = Dataset['smoker'].replace(['yes','no'],[1,0])\n",
    "Dataset['region'] = Dataset['region'].replace(['southwest','southeast','northwest','northeast'],[0,1,2,3])\n",
    "\n",
    "sns.heatmap(Dataset.corr(),annot=True,cmap='Blues')\n",
    "plt.title('correlation of Insurance Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verwijder_outliers(df_input, df_input_col):\n",
    "    # Bereken de outliers\n",
    "    percentage_aantal_outliers = bereken_percentage_aantal_outliers(df_input, df_input_col)\n",
    "    print(percentage_aantal_outliers)\n",
    "    log_info(f\"Check op de outliers in kolom {df_input_col} : {percentage_aantal_outliers}\")\n",
    "\n",
    "    df_output = df_input.copy()\n",
    "    for col in df_input_col:\n",
    "        df_output = cap_values(df_output, col)    \n",
    "\n",
    "    percentage_aantal_outliers = bereken_percentage_aantal_outliers(df_output, df_input_col)\n",
    "    print(percentage_aantal_outliers)\n",
    "    # plot_boxplot(df, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "    log_info(f\"Check op de outliers in kolom [bmi, charges] na capping op kolom [bmi]  : {percentage_aantal_outliers}\")\n",
    "    log_info(\"Capping wordt niet toegepast op de dataset\")\n",
    "\n",
    "    return df_output\n",
    "\n",
    "plot_boxplot(df_original, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "df_zonder_outliers = verwijder_outliers(df_original,['bmi'])\n",
    "plot_boxplot(df_zonder_outliers, df_num_col,\"Boxplot en histogram na removing van de outliers\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature preparation\n",
    "# standard scaler op de numerische waarden, min-max scaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"standardize\", StandardScaler()),\n",
    "])\n",
    "\n",
    "#set_matplotlib_closeV_encoder = BinaryValueEncoder(\"male\",\"female\")\n",
    "#set_matplotlib_smoking_encoder = BinaryValueEncoder(\"yes\",\"no\")\n",
    "# bv_encoder = PredefinedBinaryCategoricalEncoder(positive_class='female')\n",
    "\n",
    "male_female_transformer = Pipeline(steps=[\n",
    "     #('male_female_encoder', BinaryValueEncoder(\"male\",\"female\"))\n",
    "    ('male_female_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "smoking_transformer = Pipeline(steps=[\n",
    "    #('smoking_encoder', BinaryValueEncoder(\"yes\",\"no\"))\n",
    "    ('smoking_encoder', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "regio_transformer = Pipeline(steps=[\n",
    "    ('regio', OneHotEncoder(drop='first', handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, df_num_col),\n",
    "    (\"male_female\", male_female_transformer, ['sex']), \n",
    "    (\"smoker\", smoking_transformer, ['smoker']), \n",
    "    (\"regio\", regio_transformer, ['region'])],\n",
    "     remainder='passthrough')\n",
    "\n",
    "df_features = df_original.drop(['charges'], axis= 1)\n",
    "np_prepared =  preprocessing.fit_transform(df_features)\n",
    "\n",
    "# really hacking !!! get_feature_names werkt nog niet correct !!! not used now\n",
    "df_prepared_col = ['age', 'bmi','children','sex','smoker','northeast','northwest','southeast','southwest']\n",
    "\n",
    "df_prepared = pd.DataFrame(\n",
    "    np_prepared,\n",
    "    #columns=preprocessing.get_feature_names_out(),\n",
    "    columns = [name.split('__')[-1] for name in preprocessing.get_feature_names_out()],\n",
    "    #columns = df_prepared_col,\n",
    "    index=df_original.index)\n",
    "\n",
    "df_prepared.head()\n",
    "\n",
    "plot_boxplot(df_prepared,df_num_col,\"Boxplot van numerische waarden na standard scaling\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excute_regression_models(X_train, X_test, y_train,y_test):\n",
    "    best_XGB_params = {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
    "                       \n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Lasso': Lasso(alpha=0.1) ,\n",
    "        'Ridge': Ridge(alpha=0.01) ,\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "        'XGBRegressor': XGBRegressor(random_state=42, params = best_XGB_params)\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        # Cross validation\n",
    "        mean_rmse = np.sqrt(-cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean())\n",
    "        mean_r2 = cross_val_score(model, X_train, y_train, cv=5, scoring='r2').mean()      \n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        results.append([name, mean_rmse, mean_r2, test_rmse, test_r2, test_mape])\n",
    "    df = pd.DataFrame(results, columns=['model', 'mean_rmse', 'mean_r2', 'test_rmse', 'test_r2', 'test_mape\"'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excute_regression_models_with_pipeline(X_train, X_test, y_train,y_test,preprocessor):\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Lasso': Lasso(alpha=0.1) ,\n",
    "        'Ridge': Ridge(alpha=0.01) ,\n",
    "        'Random Forest': RandomForestRegressor(random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(random_state=42), \n",
    "        'Decision Tree': DecisionTreeRegressor(random_state=42), \n",
    "        'XGBRegressor': XGBRegressor(random_state=42, learning)\n",
    "    }\n",
    "\n",
    "   # learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8\n",
    "\n",
    "    results = []\n",
    "    for name, model in models.items():        \n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "            ('regressor', model)\n",
    "        ])\n",
    "\n",
    "        pipeline\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "        results.append([name, test_rmse, test_r2, test_mape])\n",
    "    df = pd.DataFrame(results, columns=['model', 'test_rmse', 'test_r2', 'test_mape'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prepared.copy()\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "resultaat_eenvoudig = excute_regression_models(X_train, X_test, y_train, y_test)\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"\")\n",
    "log_info(\"Regression models with no stratefy\")\n",
    "log_info(resultaat_eenvoudig)\n",
    "log_info(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_prepared.copy()\n",
    "y = df_original['charges']\n",
    "df = df_original.copy()\n",
    "df[\"charges_cat\"] = pd.cut(df[\"charges\"], bins=[0, 20000,30000, np.inf], labels=[1, 2, 3])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df[\"charges_cat\"] , test_size=0.2, random_state=42)\n",
    "resultaat_eenvoudig = excute_regression_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, np.inf\")\n",
    "log_info(\"Regresison models with stratefy\")\n",
    "log_info(\"\")\n",
    "log_info(resultaat_eenvoudig)\n",
    "log_info(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "resultaat_eenvoudig = excute_regression_models_with_pipeline(X_train, X_test, y_train, y_test, preprocessing)\n",
    "\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"\")\n",
    "log_info(\"Regression models with polynomial features, no stratefy\")\n",
    "log_info(resultaat_eenvoudig)\n",
    "log_info(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(['charges'], axis=1)\n",
    "y = df_original['charges']\n",
    "\n",
    "df = df_original.copy()\n",
    "df[\"charges_cat\"] = pd.cut(df[\"charges\"], bins=[0, 20000,30000, np.inf], labels=[1, 2, 3])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df[\"charges_cat\"] , test_size=0.2, random_state=42)\n",
    "resultaat_eenvoudig = excute_regression_models_with_pipeline(X_train, X_test, y_train, y_test, preprocessing)\n",
    "\n",
    "print(resultaat_eenvoudig)\n",
    "log_info(\"\")\n",
    "log_info(\"Stratify on charges_cat: extra feature engineering: charges omzetten naar categories : bins=[0, 20000, 30000, np.inf\")\n",
    "log_info(\"Regression models polynomial features en stratify on charges_cat\")\n",
    "log_info(resultaat_eenvoudig)\n",
    "log_info(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tuning voor XGSBoost\n",
    "\n",
    "df_features = df_original.drop(['charges'], axis= 1)\n",
    "np_prepared =  preprocessing.fit_transform(df_features)\n",
    "\n",
    "# really hacking !!! get_feature_names werkt nog niet correct !!! not used now\n",
    "df_prepared_col = ['age', 'bmi','children','sex','smoker','northeast','northwest','southeast','southwest']\n",
    "\n",
    "df_prepared = pd.DataFrame(\n",
    "    np_prepared,\n",
    "    #columns=preprocessing.get_feature_names_out(),\n",
    "    columns = [name.split('__')[-1] for name in preprocessing.get_feature_names_out()],\n",
    "    #columns = df_prepared_col,\n",
    "    index=df_original.index)\n",
    "\n",
    "df_prepared.head()\n",
    "\n",
    "\n",
    "X = df_prepared\n",
    "y = df_original['charges']\n",
    "\n",
    "df = df_original.copy()\n",
    "df[\"charges_cat\"] = pd.cut(df[\"charges\"], bins=[0, 20000,30000, np.inf], labels=[1, 2, 3])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=df[\"charges_cat\"] , test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# GridSearchCV opzetten\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Beste parameters en beste score printen\n",
    "print(\"Beste parameters:\", grid_search.best_params_)\n",
    "print(\"Beste score:\", -grid_search.best_score_)  # converteer negatieve MSE terug naar positieve waarde\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_info_write_to_file(\"LinReg_logging.log\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
